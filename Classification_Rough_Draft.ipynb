{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CHE542\n",
    "#### HOMEWORK 4: *Classification on a MoleculeNet Dataset* |  ChEMBL "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *Task*\n",
    "Given a Protein Receptor, Classify which compounds are significantly active and which compounds display negligible activity. \n",
    "\n",
    "- After Training, A Binary Classification Model Can Perform A Virtual Screen\n",
    "    \n",
    "Below, the physical process of screening a compound library against a protein receptor is shown. \n",
    "![Getting Started](Single_Target_AssayPNG.PNG)\n",
    "A classifier trained on assay/screening data would assign compounds a label (active or inactive) instead producing physical measurements such as IC50.\n",
    " \n",
    " \n",
    "\n",
    "The 'final result' of this notebook are binary classifiers which appear capable of performing virtual assays with an encouraging degree of accuracy. Given a Receptor has a large enough assay size (about 500 or more compounds), we can predict which compounds will display significant activity at a rate between 30 and 65 percent accuracy. In general, the active compounds comprise about 10% of the dataset, so the model strongly outperforms a random guess. At the same time, the model correctly predicts inactive compounds between 93 and 98 percent of the time, implying there are few missed opportunities in terms of active compounds going unrecognized. \n",
    "\n",
    "Virtual Screening, of course, is a long-established task in Cheminformatics and can be carried out in different ways, as well as at different levels of resolution. Ligand-Based Virtual Screening consider only information about the compounds (their molecular features implied via SMILES)and their inhibitory effect on the target of interest. QSAR models and Similarity Searches (2-D and 3-D)are common examples.\n",
    "\n",
    "Structure-Based Virtual Screening, on the other hand, incorporates knowledge about the Ligand-Protein complex as well and is consequently more costly. The proposed binary classifier would be another example of a Ligand-Based VS.\n",
    "\n",
    "##### Virtual Screening In Practice\n",
    "\n",
    "Workflows commonly include multiple types of virtual screens used sequentially to whittle a compound library down to a handful of promising candidates.\n",
    "\n",
    "                            \n",
    "![virtual_screening-2.PNG](attachment:virtual_screening-2.PNG)\n",
    "\n",
    "\n",
    "                            A) Binary Classifier, 2D Similarity Search, QSAR Models\n",
    "\n",
    "                            B) 3D Similarity Search\n",
    "\n",
    "                            C) Docking\n",
    "\n",
    "                            D) FEP+\n",
    "\n",
    "                            E) Physical Assay (Ground Truth)\n",
    "\n",
    "\n",
    "While the final result of this notebook is a binary classifier,a plethora of powerful models capable of Ligand-Based Virtual Screening already exist. Instead, the central motivation largely comes from creating a *Multi-Label Classifier*.\n",
    "\n",
    "\n",
    "Such a model would be different from any of the previously discussed virtual screens because it would consider activity data for compounds across multiple targets  This narrative, rather than single-target classification, is present for the first half of the notebook and culminates in the construction of a Multi-Target DataFrame where the rows are compounds and the columns are Receptors (Targets).The second half examines what happens if we train a binary classifier on individual columns (single target) from this Multi-Target DataFrame.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  **Motivation**\n",
    "\n",
    "#### *Mimic Proprietary Multi-Target Datasets Using Public Data*\n",
    " \n",
    "\n",
    "#### Example: Merck Kinase Dataset (Proprietary)\n",
    "This dataset can also be accessed via deepchem's MoleculeNet. Here is how it is described in the documentation ().\n",
    "\n",
    "\"It contains 2500 Merck in-house compounds that were measured for IC50 of inhibition on 99 protein kinases. Unlike most of the other datasets featured in MoleculeNet, the Kinase collection does not have structures for the compounds tested since they were proprietary Merck compounds. However, the collection does feature pre-computed descriptors for these compounds.\"\n",
    "\n",
    "\n",
    "Because *each* of the 2,500 compounds is assayed against *all* 99 kinases, the knowledge contained in such a dataset is remarkably informative\n",
    "In the Merck Dataset, we can imagine the physical screening process is repeated over all 99 targets. For each kinase, the most active compounds (and their respective structures) can be studied in order to form a pharmacophore. If there are multiple structurally unique active compounds, the same process will produce a set of pharmacophores. Thus, for each kinase, we can use its associated pharmacophores to construct crude illustrations of known optimal binding modes. We can also extend this notion beyond a single kinase to families of kinases. For example, we can examine if any commonalities exist between all the pharmacophores in a family. The differences between pharmacophores of closely related kinases may even be leveraged to highlight which features are most specific to a kinase. Although this explorative approach remains untested, we can try to implemenent its predictive counter part. \n",
    "\n",
    "## *Multi-Label Classification Model*\n",
    "Given a Multi-Target DataFrame (rows = Compound Library, columns = Receptor Set), we can train a multi-label classification model which can recieve an input compound and predict the kinases it will be active for. \n",
    "\n",
    "A Multi-Label classification model can take some input as a subject and assign which labels apply to it. For example, it could be trained on images of animals and afterwards be asked to identify which types of animals are present in any given image. Inputs may belong to one or multiple labels. Here, the image contains *both* a cat and a bird:\n",
    "\n",
    "![Multi-Label.PNG](attachment:Multi-Label.PNG)\n",
    "\n",
    "Because our classifier would receive a molecule as input and assign which receptors it will be active for, it would closely resemble the previous example:\n",
    "![alt text](New_name.PNG \"Title\")\n",
    "\n",
    "\n",
    "### *Receptor Families* \n",
    "\n",
    "Using a classifier trained on Multi-Target data is similar in spirit to studying the selectivity of a compound by assaying it against other, off-target kinases in the kinome.\n",
    "\n",
    "For example, the kinome map below represents 500 protein receptors and 6 compounds assayed against a subset (113) of these kinases. We can compare the compounds by studying which kinases they inhibit and which they do not. Although each compound is assayed against all 113 kinases those with negligible activity are not circled in red. On the other hand, the magnitude of the circle represents the degree of inhibition. \n",
    "##### Kinome Map\n",
    "\n",
    "![Getting Started](kinome.jpg)\n",
    "\n",
    "###### **Some compounds such as *Valatonib* are more selective because they show activity for a small subset of targets (selective), while others (*Stuarospirine*) are active across a much wider range.**\n",
    "![Getting Started](kinome_tree_selectivity.PNG)\n",
    "\n",
    "#### Classification Model as  Analog \n",
    "We could imagine a multi-label classifier trained on the Merck dataset as a similar but virtual process in which the kinase subset size is 99 and the red circles are equal magnitude. In other words, we can only classify a compound as active or inactive. Additionally, there may be other benefits to using a predictive model on this dataset such as using feature importance to rank molecular features most relevant for potency. The biggest issue here is that the full, non-anonymized data is not publically available. The question which arises, then, is how close can we get for free? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Notebook Goals\n",
    "  1) *Create a Multi-Target DataFrame from a publically available source*\n",
    "     \n",
    "Merck's DataFrame is 2,500 rows (compounds) and 99 columns (kinases).This equals 247,500 unique compound-target activities. I have access to the ChEMBL database which includes thousands of protein receptors and hundreds of thousands of compounds. I will try to create the largest Multi-Target Dataset possible from this. Of course, we are no longer working with specifically kinases with ChEMBL, but all protein receptors.\n",
    "\n",
    "\n",
    " 2)  *Create a Binary Classification Model Capable of Performing Ligand-Based Virtual Screening*\n",
    "\n",
    "Because Multi-Label classification is harder, let's split apart our Multi-Target DataFrame into a series of single targets. If Single Label classification has very poor success, it does not make sense to try multi-label and points to issues with informative capacity of the data. Further discussion of Multi-Target Classification approaches is reserved at the end of this notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1: Multi-Target DataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Initial ChEMBL Target Activity Data Through MoleculeNet\n",
    "- Use 5thresh Subset to narrow Down Full ChEMBL dataset to Targets with 5 or more compounds assayed against them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-04T15:44:11.516720Z",
     "start_time": "2024-11-04T15:44:11.162107Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dc' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m chembl_tasks, datasets, transformers \u001b[38;5;241m=\u001b[39m \u001b[43mdc\u001b[49m\u001b[38;5;241m.\u001b[39mmolnet\u001b[38;5;241m.\u001b[39mload_chembl(\u001b[38;5;28mset\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m5thresh\u001b[39m\u001b[38;5;124m'\u001b[39m,reload\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\u001b[38;5;66;03m#Multiple Comments on this line, Check associated text file \u001b[39;00m\n\u001b[0;32m      2\u001b[0m train, valid, test \u001b[38;5;241m=\u001b[39m datasets \u001b[38;5;66;03m# Similarly following doc. convention, and I am only interested in train for now and regard instead as my inital dataset\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'dc' is not defined"
     ]
    }
   ],
   "source": [
    "chembl_tasks, datasets, transformers = dc.molnet.load_chembl(set= '5thresh',reload=False)#Multiple Comments on this line, Check associated text file \n",
    "train, valid, test = datasets # Similarly following doc. convention, and I am only interested in train for now and regard instead as my inital dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Code Chunk 0; Extract Multi-Target Data \n",
    "\n",
    "The output of this code chunk represents our initial multi-target DataFrame. There are 19,096 rows and 691 columns \n",
    "\n",
    "- Column Perspective: Each column is a protein/receptor (target) and its entries are compounds assayed against it. \n",
    "\n",
    "- Row Perspective: Each row is a compound and its entries are proteins assayed against it.\n",
    "\n",
    "For compounds which have never been assayed against a target, we should expect there to be no data (NaN). However initial inspection shows that the initial matrix does not include any NaN. \n",
    "\n",
    "For further comments about the code, please consult the associated text file.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-11-04T15:43:48.425Z"
    }
   },
   "outputs": [],
   "source": [
    "Y = pd.DataFrame(train.y)\n",
    "Y.index = train.ids\n",
    "for col in Y.columns: #Add Target tag to columns in Y (prevents column name ambiguity down the road) \n",
    "    Y.rename(columns={col:f\"Target {col}\"},inplace=True)\n",
    "print(f'DataFrame shape: {Y.shape[0]} Columns, {Y.shape[1]} Rows ')\n",
    "Y.head()# FIRST FIVE ROWS SHOWN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Pre-Processing \n",
    "\n",
    "Elimimate duplicates by canonicalizing SMILES and dropping rows with identical indices to ensure rows each is a unique molecule\n",
    "\n",
    "*We can see that the DF length remains unchanged (19,096), so we have no duplicates*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-11-04T15:43:48.440Z"
    }
   },
   "outputs": [],
   "source": [
    "#Canonicalization Step\n",
    "Y.index=[MolToSmiles(MolFromSmiles(compound_smiles,sanitize=False),canonical=True) for compound_smiles in Y.index]\n",
    "# Dropping Duplicate Indices Step\n",
    "Y.reset_index().drop_duplicates(subset='index', keep='last').set_index('index').shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Inital Exploration**\n",
    "\n",
    "\n",
    "We have 691 columns (Targets/Receptors), where each column has 19,096 entries. Of course, not all of the 19,096 compounds will have activity data for the Target. In fact, we would expect most entries to be NaN for any given target. \n",
    "\n",
    "Therefore, for each Target we must filter out the set of compounds it was not assayed against.   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Examining a Single Target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-11-04T15:43:48.456Z"
    }
   },
   "outputs": [],
   "source": [
    "Single_Target = pd.DataFrame(Y['Target 237'])\n",
    "Single_Target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Although crude, plotting the activity for a single receptor (Target 237) shows the activity type may be Inhibition measured as IC50 uM because many values range between 2 and 5. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-11-04T15:43:48.464Z"
    }
   },
   "outputs": [],
   "source": [
    "Single_Target.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating a histogram reveals that a single, negative measurement occurs extremely frequently. Outside of this, the values are similar to those of Inhibition measured in uM.\n",
    "\n",
    "This, combined with the fact that negative activity data (IC50,Ki, etc.) is logically impossible, means the single, oft-repeating negative value is likely notation for NaN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-11-04T15:43:48.472Z"
    }
   },
   "outputs": [],
   "source": [
    "Single_Target.hist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we convert negative values to NaN and according drop rows (compounds) with NaN entries, we can access the set of assayed compounds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-11-04T15:43:48.483Z"
    }
   },
   "outputs": [],
   "source": [
    "Y[Y <= 0] \n",
    "Y[Y <= 0] = np.nan # From above discussion , negative IC50 is impossible + repeating single val likely means Nan \n",
    "Single_Target_Filtered = pd.DataFrame(Y['Target 237']).dropna() # removes NaN rows\n",
    "Single_Target_Filtered"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, if we re-create a the two graphs before, it is clear the activity data for Target 237 takes on similar values to an inhibiton assay measured in uM. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-11-04T15:43:48.490Z"
    }
   },
   "outputs": [],
   "source": [
    "Single_Target_Filtered.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-11-04T15:43:48.496Z"
    }
   },
   "outputs": [],
   "source": [
    "Single_Target_Filtered.hist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CODE CHUNK 1; **Sort Targets by size of Assay**\n",
    "\n",
    "Return List where each item is a Column (Target) of varying length only containing activity.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-11-04T15:43:48.506Z"
    }
   },
   "outputs": [],
   "source": [
    "Y = Y.loc[:, (Y != 0).any(axis=0)]\n",
    "backup = Y.copy()\n",
    "only_hits_dfs = []\n",
    "for i,col in enumerate(Y):\n",
    "    only_hits_dfs.append(pd.DataFrame(Y[col].dropna())\n",
    ")\n",
    "    \n",
    "\n",
    "many_hits = []\n",
    "for i,df in enumerate(only_hits_dfs):\n",
    "    df = df[df.columns[0]]\n",
    "    if len(df)>300:\n",
    "        #print(len(df))\n",
    "        #print(i)\n",
    "        many_hits.append(df)\n",
    "many_hits.sort(key=len)\n",
    "many_hits.reverse()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-31T00:04:56.721297Z",
     "start_time": "2024-10-31T00:04:56.716617Z"
    }
   },
   "source": [
    "##### We can see Target 237 is the largest with 1,921 compounds assayed against it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-11-04T15:43:48.515Z"
    }
   },
   "outputs": [],
   "source": [
    "pd.DataFrame(many_hits[0]) # This is the most commonly assayed Target.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The 20th largest assay belongs to Target 150 with 631 compounds tested against it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-11-04T15:43:48.524Z"
    }
   },
   "outputs": [],
   "source": [
    "pd.DataFrame(many_hits[20]) # This is the most commonly assayed Target.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Checkpoint Saturday Night"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-31T17:49:06.969490Z",
     "start_time": "2024-10-31T17:49:06.965049Z"
    }
   },
   "source": [
    "### Code Chunk 2; Create Largest Possible Multi-Target DataFrame\n",
    "\n",
    "Many approaches which guarantee larger dataframes, I take the simplest aprroach. Start with the largest Target (assay size) and add the next largest assay with the highest compound overlap. With this new dataset (2 targers by x number of shared compounds) try the same thing and repeat until adding a new target loses too much data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-11-04T15:43:48.535Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "all_things = []\n",
    "for J,item in enumerate(many_hits[13:15]):\n",
    "    new_base=pd.DataFrame(Y[many_hits[J].name]).copy()\n",
    "    end_range = len(many_hits)-2\n",
    "    for i,target in enumerate(many_hits[1:end_range]):\n",
    "        if i == 0:\n",
    "            base = new_base.copy()\n",
    "        else:\n",
    "            base = merged_df\n",
    "        other_hits_series = many_hits[i+1:]\n",
    "        local_running_total =0\n",
    "        for j,o in enumerate(other_hits_series):\n",
    "            #print(o.name)\n",
    "            #print(local_running_total)\n",
    "            df_o = pd.DataFrame(Y[o.name]).copy()\n",
    "            if len([x for x in df_o.columns.intersection(base.columns)])==0:\n",
    "                #print(base.columns)\n",
    "                other_merged_df = pd.merge(df_o,base,how='inner',right_index=True,left_index=True).dropna(axis=0,how='any')\n",
    "                other_merged_cell_count = other_merged_df.shape[0] * other_merged_df.shape[1]\n",
    "                if other_merged_cell_count > 0:\n",
    "                    if other_merged_cell_count == local_running_total:\n",
    "                        #print(local_running_total)\n",
    "                        #print('weird tie case, rpobbaly include both which adds more data!. For now reducing to 1 (favoring newst)') \n",
    "                        pass\n",
    "                if other_merged_cell_count>local_running_total:\n",
    "                    local_running_total = other_merged_cell_count\n",
    "                    current_merge_choice = other_merged_df\n",
    "                    #print(f'{local_running_total} {i}')    \n",
    "        if local_running_total==0:\n",
    "            #print('no merge amongst any of the others')\n",
    "            current_merge_choice = None\n",
    "        else:\n",
    "            if current_merge_choice is not None:\n",
    "                #print(i)\n",
    "                #print(base.columns)\n",
    "                #print(current_merge_choice.columns)\n",
    "                merged_df_cell_count = current_merge_choice.shape[0]*current_merge_choice.shape[1]\n",
    "                base_cell_count = base.shape[0]*base.shape[1]     \n",
    "                if (merged_df_cell_count>base_cell_count) and (i>0):\n",
    "                    #print(f'Running Total Cell Count: {base_cell_count}... Current Total: {merged_df_cell_count}')\n",
    "                    merged_df = current_merge_choice\n",
    "                elif i == 0:\n",
    "                    #print(f'Starting Total Cell Count: {base_cell_count}... Current Total: {merged_df_cell_count}')\n",
    "                    merged_df = current_merge_choice\n",
    "                else:\n",
    "                    merged_df = base\n",
    "            else:\n",
    "                merged_df = base\n",
    "    if len(merged_df)>1:\n",
    "        print('yes')\n",
    "        all_things.append(merged_df)\n",
    "\n",
    "all_things.sort(key=len)\n",
    "all_things.reverse()\n",
    "all_things[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-11-04T15:43:48.541Z"
    }
   },
   "outputs": [],
   "source": [
    " 1204*4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *How Much Information Does The Largest Multi-Target DataFrame Contain?*\n",
    "The DataFrame contains 1,204 unique compounds (rows) assayed against four unique targets (columns) or equivantly 4,816 entries (individual IC50 measurements). \n",
    "\n",
    "We can see this is about 50x smaller than the Merck Kinase Dataset! \n",
    "- Merck Multi-Target DataFrame --->2,500 compounds x 99 targets = 247,500\n",
    "\n",
    "#### Fundamental Problem: Public-Acess Activity Data Is a Patchwork\n",
    "While it is likely that there better ways to construct a larger multi-target DataFrame, it is hard to imagine that even the best approach could more than quadrouple the current size. The issue here is that public-access assay data are provided by a wide range of parties who inviariably target different receptors.One assay could come from a group wanting to target a receptor involved in cancers linked to Double-stranded DNA breaks. Another assay could be provided by a different group targeting a receptor involved in a different cancer pathway, or even a different disease entirely. \n",
    "\n",
    "*If two Receptors are unrelated, their assays share very little (oftentimes zero) compounds in common.*\n",
    "\n",
    "Because of this, despite our 691 Targets, most have only a handful of compounds in common. The rows (compounds) of a Multi-Target DataFrame are equivalent to the intersection formed between the compound libraries associated with each Target's assay. For example, if three targets share 400 compounds, but a fourth target only shares 20 in common with them, then the 4-Target DataFrame formed between them only has 20 rows. \n",
    "\n",
    "#### Imputation and Other Strategies to Include More Data\n",
    "If we relax our intersection contraints from 100% (all compounds are shared between all targets), it is much easier to construct the DataFrame and find suitable sets of Targets. While this introduces entries with unknown values (no assay for compound-target), it may be possible to approximate their values through imputation. Further discussion of imputation and other ideas aimed at increasing the maximum size of a Multi-Target DataFrame are reserved for the conclusion and remain hypothetical. \n",
    "\n",
    "Instead, the implemented solution leverages the patchwork nature of the ChEMBL assay data to produce a collection of large Multi-Target DataFrames. This increases the number of unique entries (compound-target activity measurement) from 4,816 to 32,000 which is about 7x smaller than Merck .  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Breadth Approach \n",
    "\n",
    "We want to find find the patches. T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-11-04T15:43:48.551Z"
    }
   },
   "outputs": [],
   "source": [
    "unused_hits=[df for df in many_hits if df.name not in base.columns] \n",
    "many_hits = unused_hits\n",
    "new_base=merged_df = pd.DataFrame(Y[many_hits[0].name]).copy()\n",
    "\n",
    "end_range = len(many_hits)-2\n",
    "for i,target in enumerate(many_hits[1:end_range]):\n",
    "    if i == 0:\n",
    "        base = new_base.copy()\n",
    "    else:\n",
    "        base = merged_df\n",
    "    other_hits_series = many_hits[i+1:]\n",
    "    local_running_total =0\n",
    "    for j,o in enumerate(other_hits_series):\n",
    "        #print(o.name)\n",
    "        #print(local_running_total)\n",
    "        df_o = pd.DataFrame(Y[o.name]).copy()\n",
    "        if len([x for x in df_o.columns.intersection(base.columns)])==0:\n",
    "            #print(base.columns)\n",
    "            other_merged_df = pd.merge(df_o,base,how='inner',right_index=True,left_index=True).dropna(axis=0,how='any')\n",
    "            other_merged_cell_count = other_merged_df.shape[0] * other_merged_df.shape[1]\n",
    "            if other_merged_cell_count > 0:\n",
    "                if other_merged_cell_count == local_running_total:\n",
    "                    #print(local_running_total)\n",
    "                    #print('weird tie case, rpobbaly include both which adds more data!. For now reducing to 1 (favoring newst)') \n",
    "                    pass\n",
    "            if other_merged_cell_count>local_running_total:\n",
    "                local_running_total = other_merged_cell_count\n",
    "                current_merge_choice = other_merged_df\n",
    "                #print(f'{local_running_total} {i}')    \n",
    "    if local_running_total==0:\n",
    "        #print('no merge amongst any of the others')\n",
    "        current_merge_choice = None\n",
    "    else:\n",
    "        if current_merge_choice is not None:\n",
    "            #print(i)\n",
    "            #print(base.columns)\n",
    "            #print(current_merge_choice.columns)\n",
    "            merged_df_cell_count = current_merge_choice.shape[0]*current_merge_choice.shape[1]\n",
    "            base_cell_count = base.shape[0]*base.shape[1]     \n",
    "            if (merged_df_cell_count>base_cell_count) and (i>0):\n",
    "                print(f'Running Total Cell Count: {base_cell_count}... Current Total: {merged_df_cell_count}')\n",
    "                merged_df4 = current_merge_choice\n",
    "            elif i == 0:\n",
    "                print(f'Starting Total Cell Count: {base_cell_count}... Current Total: {merged_df_cell_count}')\n",
    "                merged_df4 = current_merge_choice\n",
    "            else:\n",
    "                merged_df4 = base\n",
    "        else:\n",
    "            merged_df4 = base\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-11-04T15:43:48.556Z"
    }
   },
   "outputs": [],
   "source": [
    "details = []\n",
    "for i,df in enumerate(only_hits_dfs):\n",
    "    if len(df)>300:\n",
    "        print(len(df))\n",
    "        print(i)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-11-04T15:43:48.563Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "data_matrix_0 = data_matrix.copy()\n",
    "X = data_matrix_0.iloc[:,:1024].copy()\n",
    "Y = data_matrix_0.iloc[:,1024:].copy()\n",
    "#dm = pd.concat([X,Ys])\n",
    "cleaned_lis = []\n",
    "for string in X.index:\n",
    "    lis_0 = []\n",
    "    for char in string:\n",
    "        if char !='\\\\':\n",
    "            lis_0.append(char)\n",
    "    cleaned_lis.append(''.join(lis_0))\n",
    "X.index = cleaned_lis\n",
    "\n",
    "\n",
    "#dm = pd.concat([X,Ys])\n",
    "cleaned_lis = []\n",
    "for string in Y.index:\n",
    "    lis_0 = []\n",
    "    for char in string:\n",
    "        if char !='\\\\':\n",
    "            lis_0.append(char)\n",
    "    cleaned_lis.append(''.join(lis_0))\n",
    "Y.index = cleaned_lis\n",
    "\n",
    "\n",
    "#Y[Y<=0] = np.nan\n",
    "\n",
    "Ys =np.log10(Y)*-1\n",
    "\n",
    "dm = pd.concat([X.copy(),Ys.copy()],axis=1)\n",
    "data_matrix = dm.copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-11-04T15:43:48.568Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "data_matrix_practice = data_matrix.copy()\n",
    "data_matrix_practice.index.name = 'SMILES'\n",
    "data_matrix_practice.reset_index(inplace=True)\n",
    "data_matrix_practice['SMILES']= [rdkit.Chem.MolToSmiles(rdkit.Chem.MolFromSmiles(smi)) for smi in data_matrix_practice['SMILES']]\n",
    "\n",
    "duplicates_smiles = data_matrix_practice[data_matrix_practice['SMILES'].duplicated()]['SMILES'].values\n",
    "TRUE_X = data_matrix_practice.drop_duplicates('SMILES',keep='first')\n",
    "TRUE_X.index = TRUE_X['SMILES']\n",
    "data_matrix = TRUE_X.drop(columns=['SMILES'])\n",
    "\n",
    "\n",
    "\n",
    "col_name = many_hits[0].name\n",
    "cols = [x for x in X.columns]\n",
    "X.index = [rdkit.Chem.MolToSmiles(rdkit.Chem.MolFromSmiles(smi)) for smi in X.index]\n",
    "cols.append(col_name)\n",
    "single_classifier_dm = data_matrix[cols]\n",
    "DM = single_classifier_dm.dropna(axis=0,subset=col_name)\n",
    "print(DM.shape)\n",
    "\n",
    "continous_value_DM = DM.copy()\n",
    "activity_threshold = np.percentile(continous_value_DM.loc[:,col_name], 90)\n",
    "inds = DM[col_name]<activity_threshold\n",
    "inds_a = DM[col_name]>=activity_threshold\n",
    "DM = DM.copy()\n",
    "DM.loc[inds,col_name]=0\n",
    "DM.loc[inds_a,col_name]=1\n",
    "DM.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-11-04T15:43:48.573Z"
    }
   },
   "outputs": [],
   "source": [
    "break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-11-04T15:43:48.577Z"
    }
   },
   "outputs": [],
   "source": [
    "Ys['Target 151'].hist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning Part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-11-04T15:43:48.584Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "#DM[DM[col_name]>=activity_threshold]==1\n",
    "#DM\n",
    "import sklearn \n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "\n",
    "y = DM[col_name]\n",
    "\n",
    "feature_narrowing = DM.copy().iloc[:,:-1]\n",
    "\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "\n",
    "\n",
    "def remove_low_variance(input_data,threshold=0.1):\n",
    "    selection = VarianceThreshold(threshold)\n",
    "    selection.fit(input_data)\n",
    "    return input_data[input_data.columns[selection.get_support(indices=True)]]\n",
    "def remove_highly_correlated_features(descriptors,threshold = 0.9):\n",
    "    corrleated_matrix = descriptors.corr().abs()\n",
    "    upper_triangle = corrleated_matrix.where(np.triu(np.ones(corrleated_matrix.shape),k=1).astype(bool))\n",
    "    \n",
    "    to_drop = [column for column in upper_triangle.columns if any(upper_triangle[column] >= threshold)]\n",
    "    descriptors_correlated_dropped = descriptors.drop(columns =to_drop,axis=1)\n",
    "    return descriptors_correlated_dropped\n",
    "\n",
    "feature_narrowing1 = remove_highly_correlated_features(feature_narrowing,0.80)\n",
    "feature_narrowing2= remove_low_variance(feature_narrowing1,threshold=0.01)\n",
    "\n",
    "intermediate = DM.loc[feature_narrowing2.index,:]\n",
    "y_col = intermediate.loc[:,col_name]\n",
    "DM_new = pd.concat([feature_narrowing2,pd.DataFrame(y_col)],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-11-04T15:43:48.588Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "X = DM.iloc[:,:-1]\n",
    "y = DM.iloc[:,-1]\n",
    "sklearn.neighbors.KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20,random_state=42)\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "classifier = KNeighborsClassifier(n_neighbors=5)\n",
    "classifier.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "\n",
    "y_pred = classifier.predict(X_test)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-11-04T15:43:48.592Z"
    }
   },
   "outputs": [],
   "source": [
    "import lazypredict\n",
    "X = DM.iloc[:,:-1]\n",
    "y = y_col\n",
    "\n",
    "from lazypredict.Supervised import LazyClassifier\n",
    "X_train, X_test,y_train, y_test = train_test_split(X,y,test_size=0.2,random_state=42)\n",
    "lclf = LazyClassifier(verbose=0,ignore_warnings=True,custom_metric=None)\n",
    "models,predictions = lclf.fit(X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-11-04T15:43:48.595Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-11-04T15:43:48.599Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "import lightgbm as lgb\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.neighbors import NearestCentroid\n",
    "from sklearn.ensemble import  BaggingClassifier\n",
    "from sklearn.linear_model import RidgeClassifierCV\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "\n",
    "from sklearn.linear_model import Perceptron\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "\n",
    "\n",
    "KNN = KNeighborsClassifier()\n",
    "BNB = BernoulliNB()\n",
    "NC = NearestCentroid()\n",
    "LGBM = LGBMClassifier()\n",
    "BC = BaggingClassifier()\n",
    "RC = RidgeClassifierCV()\n",
    "LR = LogisticRegression()\n",
    "LRC = LogisticRegressionCV()\n",
    "P = Perceptron()\n",
    "RF = RandomForestClassifier()\n",
    "pipe = Pipeline(\n",
    "    steps = [(\"scaler\",StandardScaler()),(('KN',LGBMClassifier()))]\n",
    ")\n",
    "\n",
    "pipe = LGBMClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-11-04T15:43:48.604Z"
    }
   },
   "outputs": [],
   "source": [
    "pipe.fit(X_train,y_train)\n",
    "y_predict = pipe.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-11-04T15:43:48.608Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import balanced_accuracy_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "print('roc_auc_score= ',roc_auc_score(y_test,y_predict))\n",
    "\n",
    "print('accur= ',accuracy_score(y_test,y_predict))\n",
    "\n",
    "print('balanced_accur= ',balanced_accuracy_score(y_test,y_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-11-04T15:43:48.612Z"
    }
   },
   "outputs": [],
   "source": [
    "y_pred_df = pd.DataFrame(y_predict)\n",
    "y_pred_df.index=X_test.index\n",
    "\n",
    "y_test_df = pd.DataFrame(y_test)\n",
    "y_test_df.index=X_test.index\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-11-04T15:43:48.616Z"
    }
   },
   "outputs": [],
   "source": [
    "score_df = pd.concat([y_pred_df,y_test_df],axis=1)\n",
    "score_df['Pred - Label'] = score_df[score_df.columns[0]] - score_df[score_df.columns[1]]\n",
    "df = score_df\n",
    "#df.loc[(df!=0).any(axis=1)]\n",
    "relevant_score_card = df.loc[~(df==0).all(axis=1)]\n",
    "\n",
    "correct_Active_Prediction = relevant_score_card[relevant_score_card[relevant_score_card.columns[-1]]==0]\n",
    "missed_Active = relevant_score_card[relevant_score_card[relevant_score_card.columns[-1]]==-1]\n",
    "incorrect_labeled_active = relevant_score_card[relevant_score_card[relevant_score_card.columns[-1]]==1]\n",
    "correct_inactive = relevant_score_card[relevant_score_card[relevant_score_card.columns[-1]]==0]\n",
    "\n",
    "resto = df[df[[df.columns[0],df.columns[1]]]==0][df.columns[:2]]\n",
    "correct_active = resto.dropna(how='any')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-11-04T15:43:48.619Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "ALL_ACTIVES = pd.concat([correct_Active_Prediction,missed_Active])\n",
    "number_incorrectly_correctly_guessed = ALL_ACTIVES['Pred - Label'].sum()*-1\n",
    "number_correctly_guessed = len(ALL_ACTIVES)-number_incorrectly_correctly_guessed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-11-04T15:43:48.627Z"
    }
   },
   "outputs": [],
   "source": [
    "total = len(ALL_ACTIVES)\n",
    "true_null_cases = len(y_test)-len(ALL_ACTIVES)\n",
    "print(f'Test_Size = {len(y_test)}')\n",
    "print(f'Number of  Active Labels = {len(ALL_ACTIVES)}')\n",
    "print(f\"True_Cases/All_Cases = {np.round((total/len(y_test)*100))}%\")\n",
    "\n",
    "print('---------Comparing Ground Truth To Model Prediction  ----------------')\n",
    "print(f\"Detection = {np.round(number_correctly_guessed/total*100)}%\" )\n",
    "print(f'Sensitivity = made {number_correctly_guessed} out of {total}')\n",
    "print(f'#False Alarms/# Null Cases = {np.round(len(incorrect_labeled_active)/true_null_cases*100).round()}%----->Specificity = 1-that')\n",
    "\n",
    "print(f'Inactive Correctly Guessed {len(correct_active)}; out of {len(y_test)-(len(ALL_ACTIVES))} Inactives')\n",
    "print(' ')\n",
    "print(' ')\n",
    "print('**Note**')\n",
    "print('H0==H0 removed in DF below. Showing actual score core card would show all zeros... most common event--> Guessing Inactive Correctly ')\n",
    "relevant_score_card.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-11-04T15:43:48.631Z"
    }
   },
   "outputs": [],
   "source": [
    "total = len(ALL_ACTIVES)\n",
    "true_null_cases = len(y_test)-len(ALL_ACTIVES)\n",
    "print(y_test.name)\n",
    "print(f'Test_Size = {len(y_test)}')\n",
    "print(f'Number of  Active Labels = {len(ALL_ACTIVES)}')\n",
    "print(f\"True_Cases/All_Cases = {np.round((total/len(y_test)*100))}%\")\n",
    "\n",
    "print('---------Comparing Ground Truth To Model Prediction  ----------------')\n",
    "print(f\"Detection = {np.round(number_correctly_guessed/total*100)}%\" )\n",
    "print(f'Sensitivity = made {number_correctly_guessed} out of {total}')\n",
    "print(f'#False Alarms/# Null Cases = {np.round(len(incorrect_labeled_active)/true_null_cases*100).round()}%----->Specificity = 1-that')\n",
    "\n",
    "print(f'Inactive Correctly Guessed {len(correct_active)}; out of {len(y_test)-(len(ALL_ACTIVES))} Inactives')\n",
    "print(' ')\n",
    "print(' ')\n",
    "print('**Note**')\n",
    "print('H0==H0 removed in DF below. Showing actual score core card would show all zeros... most common event--> Guessing Inactive Correctly ')\n",
    "relevant_score_card.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-11-04T15:43:48.635Z"
    }
   },
   "outputs": [],
   "source": [
    "Ys[y_test.name].dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-11-04T15:43:48.639Z"
    }
   },
   "outputs": [],
   "source": [
    "Ys[y_test.name].hist()\n",
    "\n",
    "\n",
    "np.percentile(Ys[y_test.name].dropna(), 95)\n",
    "\n",
    "\n",
    "# importing the modules\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# specifying the plot size\n",
    "plt.figure(figsize = (10, 5))\n",
    "\n",
    "# only one line may be specified; full height\n",
    "plt.axvline(x = 7, color = 'b', label = 'axvline - full height')\n",
    "\n",
    "# rendering plot\n",
    "plt.show()\n",
    "\n",
    "#y,percentile?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-11-04T15:43:48.642Z"
    }
   },
   "outputs": [],
   "source": [
    "((19/12)*5)*(((5.8-10.5)**2+(14.2-10.5)**2+(5.6-10.5)**2+(16.4-10.5)**2)/33.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-11-04T15:43:48.651Z"
    }
   },
   "outputs": [],
   "source": [
    "only_hits_dfs[19]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-11-04T15:43:48.655Z"
    }
   },
   "outputs": [],
   "source": [
    "import rdkit.Chem\n",
    "f1 = rdkit.Chem.MolFromSmiles('C[C@@H](O)[C@@H]1NC(=O)[C@H](CCCCN)NC(=O)[C@@H](Cc2c[nH]c3ccccc23)NC(=O)[C@H](Cc4ccc(NC(=O)NO)cc4)NC(=O)[C@@H](CSSC[C@H](NC1=O)C(=O)N[C@@H](Cc5ccc6ccccc6c5)C(=O)N)NC(=O)[C@H](N)Cc7ccc(Cl)cc7')\n",
    "f2 =  rdkit.Chem.MolFromSmiles('CC(C)F')\n",
    "test_smiles = [rd_kit_featurizer.featurize(f) for f in only_hits_dfs[19].index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-11-04T15:43:48.659Z"
    }
   },
   "outputs": [],
   "source": [
    "pipe.predict(test_smiles[10])#rd_kit_featurizer.featurize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-11-04T15:43:48.663Z"
    }
   },
   "outputs": [],
   "source": [
    "len(ALL_ACTIVES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-11-04T15:43:48.667Z"
    }
   },
   "outputs": [],
   "source": [
    "y225 = Y[225]\n",
    "y225[y225>0].hist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-11-04T15:43:48.671Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "np.percentile(continous_value_DM.loc[:,col_name], 90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-11-04T15:43:48.674Z"
    }
   },
   "outputs": [],
   "source": [
    "10**0.4745"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-11-04T15:43:48.678Z"
    }
   },
   "outputs": [],
   "source": [
    "DM['Target 225'].hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-11-04T15:43:48.681Z"
    }
   },
   "outputs": [],
   "source": [
    "ALL_ACTIVES.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-11-04T15:43:48.685Z"
    }
   },
   "outputs": [],
   "source": [
    "df_ = pd.DataFrame()\n",
    "df_['Actual'] = np.array(y_test)\n",
    "df_['Predicted'] = y_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-11-04T15:43:48.690Z"
    }
   },
   "outputs": [],
   "source": [
    "df_['Predicted'].hist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-11-04T15:43:48.693Z"
    }
   },
   "outputs": [],
   "source": [
    "many_hits[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-11-04T15:43:48.697Z"
    }
   },
   "outputs": [],
   "source": [
    "df_['Actual'].hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-11-04T15:43:48.700Z"
    }
   },
   "outputs": [],
   "source": [
    "# when you have time, recreate those 2 cool multi label medoim bar chart "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-11-04T15:43:48.704Z"
    }
   },
   "outputs": [],
   "source": [
    "pipe.get_params()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
